{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3095fde",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 評価方法\n",
    "\n",
    "分類されていないデータを認識し、どれだけ正しくカテゴリごとに分類できるかを算出した「平均精度」の高さを競い合います。\n",
    "\n",
    "今回、活用するデータはLSWMD_25519となります。\n",
    "LSWMD_25519のFailureType項目が分類されていない状態のデータに対し、正しいFailureTypeカテゴリを分類するプログラムを作成し、その平均精度を算出します。\n",
    "平均精度とは、カテゴリごとに正しく分類できる精度を平均した値です。カテゴリごとに算出した精度（Aが正しく分類された数/Aのデータ数）を足し、カテゴリ数で割ります。\n",
    "\n",
    "公平な評価を実施するために、以下の制限を設けています。\n",
    "1. 外部パッケージをインストールするためのセルとsolution関数の中身のみを編集すること\n",
    "2. 校舎のiMac上で最後のセルの実行時間が15分未満であること　（%%timeitの出力結果を確認してください）\n",
    "\n",
    "※気になる点がある場合、Discordで気軽にお問合せください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8b0f68e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # https://numpy.org/ja/\n",
    "import pandas as pd # https://pandas.pydata.org/\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea86471-32fa-46c6-a005-ad6e1f7b7f72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "外部パッケージを使用する場合、以下の方法でインストールを実施してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6be8d1cd-7df7-4b10-aa1a-e24677b50d78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 必要な外部パッケージは、以下の内容を編集しインストールしてください\n",
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install scikit-learn\n",
    "#!pip install tensorflow\n",
    "#!pip install Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a113ea05-433a-4c82-9cb1-2c8f834a0364",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "以下のsolution関数のみ編集してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cda6ad7e-8e26-4208-bdbd-3fa37e79c82c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def solution(x_test_df, train_df):\n",
    "    import os\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "    import tensorflow as tf\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    from PIL import Image\n",
    "    from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Add\n",
    "    from tensorflow.keras.models import Model\n",
    "\n",
    "    def resize_map(map):\n",
    "\n",
    "        resize_shape = (32, 32)\n",
    "\n",
    "        non_zero_average = np.mean(map[map != 0])\n",
    "        map[map == 0] = non_zero_average\n",
    "    \n",
    "        map = Image.fromarray(map - 1.0)\n",
    "        resized_map = map.resize(resize_shape, Image.LANCZOS)\n",
    "\n",
    "        return np.asarray(resized_map)\n",
    "\n",
    "    \n",
    "    def preprocess_map(df, resize_map):\n",
    "\n",
    "        preprocessed_maps = np.array([resize_map(x) for x in df['waferMap']])\n",
    "    \n",
    "        flipped_horizontally = np.flip(preprocessed_maps, axis=2)\n",
    "        preprocessed_maps = np.concatenate((preprocessed_maps, flipped_horizontally), axis=0)\n",
    "\n",
    "        rotated_90 = np.rot90(preprocessed_maps, k=1, axes=(1, 2))\n",
    "        preprocessed_maps = np.concatenate((preprocessed_maps, rotated_90), axis=0)\n",
    "\n",
    "        rotated_180 = np.rot90(preprocessed_maps, k=2, axes=(1, 2))\n",
    "        preprocessed_maps = np.concatenate((preprocessed_maps, rotated_180), axis=0)\n",
    "\n",
    "        preprocessed_maps = preprocessed_maps.reshape(preprocessed_maps.shape + (1,))\n",
    "\n",
    "        return preprocessed_maps\n",
    "\n",
    "    \n",
    "    def initialize_cnn(input_shape, failure_types_classes):\n",
    "        inputs = Input(shape=input_shape)\n",
    "    \n",
    "        x = Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
    "        x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "        skip_connection = Conv2D(64, 1, strides=4, activation='relu', padding='same')(x)\n",
    "\n",
    "        x = Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "\n",
    "        x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "        x = Add()([x, skip_connection])\n",
    "    \n",
    "        x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "        x = Flatten()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0)(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0)(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0)(x)\n",
    "    \n",
    "        outputs = Dense(failure_types_classes)(x)\n",
    "    \n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "        return model\n",
    "\n",
    "\n",
    "    def calculate_class_weights(train_labels):\n",
    "\n",
    "        class_weights = compute_class_weight(class_weight='balanced', \n",
    "                                             classes=np.unique(train_labels), \n",
    "                                             y=train_labels)\n",
    "\n",
    "        return dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "    failure_types = list(train_df['failureType'].unique())\n",
    "\n",
    "    train_maps = preprocess_map(train_df, resize_map)\n",
    "    train_labels = np.array([failure_types.index(x) for x in train_df['failureType']] * 8)\n",
    "\n",
    "    failure_types_classes = len(failure_types)\n",
    "    input_shape = train_maps[0].shape\n",
    "\n",
    "    class_weights = calculate_class_weights(train_labels)\n",
    "\n",
    "    model = initialize_cnn(input_shape, failure_types_classes)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(train_maps, train_labels, epochs=20, batch_size=64, class_weight=class_weights)\n",
    "\n",
    "    test_maps = preprocess_map(x_test_df, resize_map)\n",
    "    map_classes = len(x_test_df['waferMap'])\n",
    "    \n",
    "    test_predictions = model.predict(test_maps)\n",
    "    aggregated_logits = np.zeros(map_classes * failure_types_classes, dtype=np.float64).reshape((map_classes, failure_types_classes))\n",
    "    for n in range(8):\n",
    "        aggregated_logits += test_predictions[map_classes * n  :map_classes * (n + 1)]\n",
    "    \n",
    "    predictions = tf.nn.softmax(aggregated_logits).numpy()\n",
    "    answer = [failure_types[x.argmax()] for x in predictions]\n",
    "    \n",
    "    return pd.DataFrame({'failureType': answer}, index=x_test_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c20f4-f775-4d9d-90c7-a3b583584edd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "solution関数は以下のように活用され、平均精度を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a31dda-7c8b-477e-9547-5c9db739f7f0",
   "metadata": {
    "deletable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1251/2871 [============>.................] - ETA: 21s - loss: 0.7745 - accuracy: 0.7117"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "\n",
    "def plot_confusion_matrix_and_accuracy(y_true, y_pred, classes):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    # Confusion matrixの計算\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "\n",
    "    # ヒートマップとしてプロット\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "\n",
    "    # 各クラスごとの正確さと最も間違えやすいクラスを表示\n",
    "    print(\"\\nClass Accuracy and Most Common Errors:\")\n",
    "    for i, class_name in enumerate(classes):\n",
    "        accuracy = cm[i, i] / cm[i, :].sum()\n",
    "        print(f\"{class_name}: Accuracy: {accuracy * 100:.2f}%\")\n",
    "        \n",
    "        # 最も間違えやすいクラスを特定\n",
    "        error_indices = cm[i, :].argsort()[-2:-1] if accuracy < 1 else []\n",
    "        for error_index in error_indices:\n",
    "            error_rate = cm[i, error_index] / cm[i, :].sum()\n",
    "            error_class = classes[error_index]\n",
    "            print(f\"    Most common error: Mistaken for {error_class} ({error_rate * 100:.2f}%)\")\n",
    "\n",
    "# データのインポート\n",
    "df=pd.read_pickle(\"../input/LSWMD_25519.pkl\")\n",
    "\n",
    "# テスト用と学習用のデータを作成（テストする際は、random_stateの値などを編集してみてください）\n",
    "train_df, test_df = train_test_split(df, stratify=df['failureType'], test_size=0.10, random_state=42)\n",
    "\n",
    "y_test_df = test_df[['failureType']]\n",
    "x_test_df = test_df.drop(columns=['failureType'])\n",
    "\n",
    "# solution関数を実行\n",
    "user_result_df = solution(x_test_df, train_df)\n",
    "plot_confusion_matrix_and_accuracy(y_test_df['failureType'], user_result_df['failureType'], df['failureType'].unique())\n",
    "\n",
    "average_accuracy = 0\n",
    "# ユーザーの提出物のフォーマット確認\n",
    "if type(y_test_df) == type(user_result_df) and y_test_df.shape == user_result_df.shape:\n",
    "    # 平均精度の計算\n",
    "    accuracies = {}\n",
    "    for failure_type in df['failureType'].unique():\n",
    "        y_test_df_by_failure_type = y_test_df[y_test_df['failureType'] == failure_type]\n",
    "        user_result_df_by_failure_type = user_result_df[y_test_df['failureType'] == failure_type]\n",
    "        matching_rows = (y_test_df_by_failure_type == user_result_df_by_failure_type).all(axis=1).sum()\n",
    "        accuracies[failure_type] = (matching_rows/(len(y_test_df_by_failure_type)))\n",
    "    \n",
    "    average_accuracy = sum(accuracies.values())/len(accuracies)\n",
    "print(f\"平均精度：{average_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379f639-69a5-41d8-8c2b-8bd5dfff1030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
