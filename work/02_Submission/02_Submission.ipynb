{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3095fde",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 評価方法\n",
    "\n",
    "分類されていないデータを認識し、どれだけ正しくカテゴリごとに分類できるかを算出した「平均精度」の高さを競い合います。\n",
    "\n",
    "今回、活用するデータはLSWMD_25519となります。\n",
    "LSWMD_25519のFailureType項目が分類されていない状態のデータに対し、正しいFailureTypeカテゴリを分類するプログラムを作成し、その平均精度を算出します。\n",
    "平均精度とは、カテゴリごとに正しく分類できる精度を平均した値です。カテゴリごとに算出した精度（Aが正しく分類された数/Aのデータ数）を足し、カテゴリ数で割ります。\n",
    "\n",
    "公平な評価を実施するために、以下の制限を設けています。\n",
    "1. 外部パッケージをインストールするためのセルとsolution関数の中身のみを編集すること\n",
    "2. 校舎のiMac上で最後のセルの実行時間が15分未満であること　（%%timeitの出力結果を確認してください）\n",
    "\n",
    "※気になる点がある場合、Discordで気軽にお問合せください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8b0f68e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # https://numpy.org/ja/\n",
    "import pandas as pd # https://pandas.pydata.org/\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea86471-32fa-46c6-a005-ad6e1f7b7f72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "外部パッケージを使用する場合、以下の方法でインストールを実施してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6be8d1cd-7df7-4b10-aa1a-e24677b50d78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 必要な外部パッケージは、以下の内容を編集しインストールしてください\n",
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install scikit-learn\n",
    "#!pip install tensorflow\n",
    "#!pip install Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a113ea05-433a-4c82-9cb1-2c8f834a0364",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "以下のsolution関数のみ編集してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cda6ad7e-8e26-4208-bdbd-3fa37e79c82c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def solution(x_test_df, train_df):\n",
    "    import os\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "    import tensorflow as tf\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    from PIL import Image\n",
    "    from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Add\n",
    "    from tensorflow.keras.models import Model\n",
    "\n",
    "    def resize_map(map):\n",
    "\n",
    "        resize_shape = (32, 32)\n",
    "\n",
    "        non_zero_average = np.mean(map[map != 0])\n",
    "        map[map == 0] = non_zero_average\n",
    "    \n",
    "        map = Image.fromarray(map - 1.0)\n",
    "        resized_map = map.resize(resize_shape, Image.LANCZOS)\n",
    "\n",
    "        return np.asarray(resized_map)\n",
    "\n",
    "    \n",
    "    def preprocess_map(df, resize_map):\n",
    "\n",
    "        preprocessed_maps = np.array([resize_map(x) for x in df['waferMap']])\n",
    "    \n",
    "        flipped_horizontally = np.flip(preprocessed_maps, axis=2)\n",
    "        preprocessed_maps = np.concatenate((preprocessed_maps, flipped_horizontally), axis=0)\n",
    "\n",
    "        rotated_90 = np.rot90(preprocessed_maps, k=1, axes=(1, 2))\n",
    "        preprocessed_maps = np.concatenate((preprocessed_maps, rotated_90), axis=0)\n",
    "\n",
    "        rotated_180 = np.rot90(preprocessed_maps, k=2, axes=(1, 2))\n",
    "        preprocessed_maps = np.concatenate((preprocessed_maps, rotated_180), axis=0)\n",
    "\n",
    "        preprocessed_maps = preprocessed_maps.reshape(preprocessed_maps.shape + (1,))\n",
    "\n",
    "        return preprocessed_maps\n",
    "\n",
    "    \n",
    "    def initialize_cnn(input_shape, failure_types_classes):\n",
    "        inputs = Input(shape=input_shape)\n",
    "    \n",
    "        x = Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
    "        x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "        skip_connection = Conv2D(128, 1, strides=8, activation='relu', padding='same')(x)\n",
    "\n",
    "        x = Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "\n",
    "        x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "        x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "        x = Add()([x, skip_connection])\n",
    "\n",
    "        x = Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "        x = Flatten()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0)(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0)(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0)(x)\n",
    "    \n",
    "        outputs = Dense(failure_types_classes)(x)\n",
    "    \n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "        return model\n",
    "\n",
    "\n",
    "    def calculate_class_weights(train_labels):\n",
    "\n",
    "        class_weights = compute_class_weight(class_weight='balanced', \n",
    "                                             classes=np.unique(train_labels), \n",
    "                                             y=train_labels)\n",
    "\n",
    "        return dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "    failure_types = list(train_df['failureType'].unique())\n",
    "\n",
    "    train_maps = preprocess_map(train_df, resize_map)\n",
    "    train_labels = np.array([failure_types.index(x) for x in train_df['failureType']] * 8)\n",
    "\n",
    "    failure_types_classes = len(failure_types)\n",
    "    input_shape = train_maps[0].shape\n",
    "\n",
    "    class_weights = calculate_class_weights(train_labels)\n",
    "\n",
    "    model = initialize_cnn(input_shape, failure_types_classes)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(train_maps, train_labels, epochs=10, batch_size=128, class_weight=class_weights)\n",
    "\n",
    "    test_maps = preprocess_map(x_test_df, resize_map)\n",
    "    map_classes = len(x_test_df['waferMap'])\n",
    "    \n",
    "    test_predictions = model.predict(test_maps)\n",
    "    aggregated_logits = np.zeros(map_classes * failure_types_classes, dtype=np.float64).reshape((map_classes, failure_types_classes))\n",
    "    for n in range(8):\n",
    "        aggregated_logits += test_predictions[map_classes * n  :map_classes * (n + 1)]\n",
    "    \n",
    "    predictions = tf.nn.softmax(aggregated_logits).numpy()\n",
    "    answer = [failure_types[x.argmax()] for x in predictions]\n",
    "    \n",
    "    return pd.DataFrame({'failureType': answer}, index=x_test_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c20f4-f775-4d9d-90c7-a3b583584edd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "solution関数は以下のように活用され、平均精度を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04a31dda-7c8b-477e-9547-5c9db739f7f0",
   "metadata": {
    "deletable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Inputs have incompatible shapes. Received shapes (2, 2, 128) and (8, 8, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-r 1 -n 1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdef plot_confusion_matrix_and_accuracy(y_true, y_pred, classes):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    import seaborn as sns\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    import matplotlib.pyplot as plt\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    from sklearn.metrics import confusion_matrix\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # Confusion matrixの計算\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    cm = confusion_matrix(y_true, y_pred, labels=classes)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # ヒートマップとしてプロット\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    plt.figure(figsize=(10, 10))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    sns.heatmap(cm, annot=True, fmt=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43md\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, cmap=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mBlues\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, xticklabels=classes, yticklabels=classes)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    plt.title(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mConfusion Matrix\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    plt.ylabel(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mActual\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    plt.xlabel(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mPredicted\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    plt.show()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # 各クラスごとの正確さと最も間違えやすいクラスを表示\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    print(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mnClass Accuracy and Most Common Errors:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    for i, class_name in enumerate(classes):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        accuracy = cm[i, i] / cm[i, :].sum()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        print(f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{class_name}\u001b[39;49;00m\u001b[38;5;124;43m: Accuracy: \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43maccuracy * 100:.2f}\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        # 最も間違えやすいクラスを特定\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        error_indices = cm[i, :].argsort()[-2:-1] if accuracy < 1 else []\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        for error_index in error_indices:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            error_rate = cm[i, error_index] / cm[i, :].sum()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            error_class = classes[error_index]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            print(f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m    Most common error: Mistaken for \u001b[39;49m\u001b[38;5;132;43;01m{error_class}\u001b[39;49;00m\u001b[38;5;124;43m (\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43merror_rate * 100:.2f}\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# データのインポート\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdf=pd.read_pickle(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../input/LSWMD_25519.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# テスト用と学習用のデータを作成（テストする際は、random_stateの値などを編集してみてください）\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mtrain_df, test_df = train_test_split(df, stratify=df[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m], test_size=0.10, random_state=42)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43my_test_df = test_df[[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m]]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mx_test_df = test_df.drop(columns=[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# solution関数を実行\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43muser_result_df = solution(x_test_df, train_df)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mplot_confusion_matrix_and_accuracy(y_test_df[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m], user_result_df[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m], df[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m].unique())\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43maverage_accuracy = 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ユーザーの提出物のフォーマット確認\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mif type(y_test_df) == type(user_result_df) and y_test_df.shape == user_result_df.shape:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # 平均精度の計算\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    accuracies = \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    for failure_type in df[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m].unique():\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        y_test_df_by_failure_type = y_test_df[y_test_df[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m] == failure_type]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        user_result_df_by_failure_type = user_result_df[y_test_df[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m] == failure_type]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        matching_rows = (y_test_df_by_failure_type == user_result_df_by_failure_type).all(axis=1).sum()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        accuracies[failure_type] = (matching_rows/(len(y_test_df_by_failure_type)))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    average_accuracy = sum(accuracies.values())/len(accuracies)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mprint(f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m平均精度：\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43maverage_accuracy*100:.2f}\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2493\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2491\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2492\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2493\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2495\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2496\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/core/magics/execution.py:1189\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1187\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m all_runs \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n\u001b[1;32m   1191\u001b[0m worst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/timeit.py:208\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    206\u001b[0m r \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[0;32m--> 208\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/core/magics/execution.py:173\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    171\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:40\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "Cell \u001b[0;32mIn[31], line 96\u001b[0m, in \u001b[0;36msolution\u001b[0;34m(x_test_df, train_df)\u001b[0m\n\u001b[1;32m     92\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m train_maps[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     94\u001b[0m class_weights \u001b[38;5;241m=\u001b[39m calculate_class_weights(train_labels)\n\u001b[0;32m---> 96\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfailure_types_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m),\n\u001b[1;32m     98\u001b[0m           loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     99\u001b[0m           metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    100\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_maps, train_labels, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39mclass_weights)\n",
      "Cell \u001b[0;32mIn[31], line 57\u001b[0m, in \u001b[0;36msolution.<locals>.initialize_cnn\u001b[0;34m(input_shape, failure_types_classes)\u001b[0m\n\u001b[1;32m     55\u001b[0m x \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     56\u001b[0m x \u001b[38;5;241m=\u001b[39m MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)(x)\n\u001b[0;32m---> 57\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mAdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_connection\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m x \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     60\u001b[0m x \u001b[38;5;241m=\u001b[39m MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/layers/merging/base_merge.py:74\u001b[0m, in \u001b[0;36m_Merge._compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[0;32m---> 74\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     75\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs have incompatible shapes. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         output_shape\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(output_shape)\n",
      "\u001b[0;31mValueError\u001b[0m: Inputs have incompatible shapes. Received shapes (2, 2, 128) and (8, 8, 128)"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "\n",
    "def plot_confusion_matrix_and_accuracy(y_true, y_pred, classes):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    # Confusion matrixの計算\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "\n",
    "    # ヒートマップとしてプロット\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "\n",
    "    # 各クラスごとの正確さと最も間違えやすいクラスを表示\n",
    "    print(\"\\nClass Accuracy and Most Common Errors:\")\n",
    "    for i, class_name in enumerate(classes):\n",
    "        accuracy = cm[i, i] / cm[i, :].sum()\n",
    "        print(f\"{class_name}: Accuracy: {accuracy * 100:.2f}%\")\n",
    "        \n",
    "        # 最も間違えやすいクラスを特定\n",
    "        error_indices = cm[i, :].argsort()[-2:-1] if accuracy < 1 else []\n",
    "        for error_index in error_indices:\n",
    "            error_rate = cm[i, error_index] / cm[i, :].sum()\n",
    "            error_class = classes[error_index]\n",
    "            print(f\"    Most common error: Mistaken for {error_class} ({error_rate * 100:.2f}%)\")\n",
    "\n",
    "# データのインポート\n",
    "df=pd.read_pickle(\"../input/LSWMD_25519.pkl\")\n",
    "\n",
    "# テスト用と学習用のデータを作成（テストする際は、random_stateの値などを編集してみてください）\n",
    "train_df, test_df = train_test_split(df, stratify=df['failureType'], test_size=0.10, random_state=42)\n",
    "\n",
    "y_test_df = test_df[['failureType']]\n",
    "x_test_df = test_df.drop(columns=['failureType'])\n",
    "\n",
    "# solution関数を実行\n",
    "user_result_df = solution(x_test_df, train_df)\n",
    "plot_confusion_matrix_and_accuracy(y_test_df['failureType'], user_result_df['failureType'], df['failureType'].unique())\n",
    "\n",
    "average_accuracy = 0\n",
    "# ユーザーの提出物のフォーマット確認\n",
    "if type(y_test_df) == type(user_result_df) and y_test_df.shape == user_result_df.shape:\n",
    "    # 平均精度の計算\n",
    "    accuracies = {}\n",
    "    for failure_type in df['failureType'].unique():\n",
    "        y_test_df_by_failure_type = y_test_df[y_test_df['failureType'] == failure_type]\n",
    "        user_result_df_by_failure_type = user_result_df[y_test_df['failureType'] == failure_type]\n",
    "        matching_rows = (y_test_df_by_failure_type == user_result_df_by_failure_type).all(axis=1).sum()\n",
    "        accuracies[failure_type] = (matching_rows/(len(y_test_df_by_failure_type)))\n",
    "    \n",
    "    average_accuracy = sum(accuracies.values())/len(accuracies)\n",
    "print(f\"平均精度：{average_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379f639-69a5-41d8-8c2b-8bd5dfff1030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
